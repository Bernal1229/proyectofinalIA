{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5962a1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 23:41:21.953905: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-20 23:41:21.957889: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-20 23:41:21.965706: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750477281.978695     329 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750477281.982365     329 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-20 23:41:21.997027: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import deap\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15183af",
   "metadata": {},
   "source": [
    "# Parametros del problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86361bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 1\n",
    "g = 9.81\n",
    "m = 0.25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfc9dde",
   "metadata": {},
   "source": [
    "# $Individuo = [W_1, B_1, W_2, B_2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5be5b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeightsPlacer(individual, tuner):\n",
    "    '''\n",
    "    Toma los pesos, que se encuentran en el individuo\n",
    "    y los convierte en forma tensorial para poder\n",
    "    ser colocados en el modelo\n",
    "    '''\n",
    "    best_config = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    model = tuner.hypermodel.build(best_config) \n",
    "    idx = 0\n",
    "    tensors=[]\n",
    "    for layer in model.layers[1:]: #Excluye la capa Normalizadora, que ya se entrenó\n",
    "        for weight_arr in layer.get_weights():\n",
    "\n",
    "            size = weight_arr.size\n",
    "\n",
    "            shape = weight_arr.shape\n",
    "            tensor = individual[idx:idx+size]\n",
    "            \n",
    "            tensor = np.array(tensor)\n",
    "            tensor = np.reshape(tensor, shape)\n",
    "\n",
    "            idx += size\n",
    "\n",
    "            tensors.append(tensor)\n",
    "\n",
    "    model.set_weights(tensors)\n",
    "\n",
    "    return model\n",
    "\n",
    "def Fitness_Function(individual, train_dataset, batch_size, step):\n",
    "    #Create the model\n",
    "     #CHANGE THIS BUILD USING HYPERPARMS\n",
    "    #Set the weights\n",
    "\n",
    "    model = WeightsPlacer(individual)\n",
    "\n",
    "    #for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "    (x_batch_train, y_batch_train) = train_dataset\n",
    "    \n",
    "    current_batch_X = x_batch_train[step*batch_size:(step+1)*batch_size]\n",
    "    current_batch_Y = y_batch_train[step*batch_size:(step+1)*batch_size]\n",
    "\n",
    "    mae_per_batch = np.abs(model.predict(x_batch_train) - y_batch_train)\n",
    "\n",
    "    Average_training_torque_error = np.mean(mae_per_batch) \n",
    "\n",
    "    return Average_training_torque\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c30d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training_Loop(population, toolbox, mu, lambda_, cxpb, mutpb, ngen,train_dataset, batch_size, step,\n",
    "                   stats=None, halloffame=None, verbose=__debug__ ):\n",
    "    r\"\"\"This is the :math:`(\\mu + \\lambda)` evolutionary algorithm.\n",
    "\n",
    "    :param population: A list of individuals.\n",
    "    :param toolbox: A :class:`~deap.base.Toolbox` that contains the evolution\n",
    "                    operators.\n",
    "    :param mu: The number of individuals to select for the next generation.\n",
    "    :param lambda\\_: The number of children to produce at each generation.\n",
    "    :param cxpb: The probability that an offspring is produced by crossover.\n",
    "    :param mutpb: The probability that an offspring is produced by mutation.\n",
    "    :param ngen: The number of generation.\n",
    "    :param stats: A :class:`~deap.tools.Statistics` object that is updated\n",
    "                  inplace, optional.\n",
    "    :param halloffame: A :class:`~deap.tools.HallOfFame` object that will\n",
    "                       contain the best individuals, optional.\n",
    "    :param verbose: Whether or not to log the statistics.\n",
    "    :returns: The final population\n",
    "    :returns: A class:`~deap.tools.Logbook` with the statistics of the\n",
    "              evolution.\n",
    "\n",
    "    The algorithm takes in a population and evolves it in place using the\n",
    "    :func:`varOr` function. It returns the optimized population and a\n",
    "    :class:`~deap.tools.Logbook` with the statistics of the evolution. The\n",
    "    logbook will contain the generation number, the number of evaluations for\n",
    "    each generation and the statistics if a :class:`~deap.tools.Statistics` is\n",
    "    given as argument. The *cxpb* and *mutpb* arguments are passed to the\n",
    "    :func:`varOr` function. The pseudocode goes as follow ::\n",
    "\n",
    "        evaluate(population)\n",
    "        for g in range(ngen):\n",
    "            offspring = varOr(population, toolbox, lambda_, cxpb, mutpb)\n",
    "            evaluate(offspring)\n",
    "            population = select(population + offspring, mu)\n",
    "\n",
    "    First, the individuals having an invalid fitness are evaluated. Second,\n",
    "    the evolutionary loop begins by producing *lambda_* offspring from the\n",
    "    population, the offspring are generated by the :func:`varOr` function. The\n",
    "    offspring are then evaluated and the next generation population is\n",
    "    selected from both the offspring **and** the population. Finally, when\n",
    "    *ngen* generations are done, the algorithm returns a tuple with the final\n",
    "    population and a :class:`~deap.tools.Logbook` of the evolution.\n",
    "\n",
    "    This function expects :meth:`toolbox.mate`, :meth:`toolbox.mutate`,\n",
    "    :meth:`toolbox.select` and :meth:`toolbox.evaluate` aliases to be\n",
    "    registered in the toolbox. This algorithm uses the :func:`varOr`\n",
    "    variation.\n",
    "    \"\"\"\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + (stats.fields if stats else [])\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitnesses = []\n",
    "    curr_step = 0\n",
    "    for ind in invalid_ind:\n",
    "        fitnesses.append(Fitness_Function(ind, train_dataset, batch_size, curr_step))\n",
    "\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    if halloffame is not None:\n",
    "        halloffame.update(population)\n",
    "\n",
    "    record = stats.compile(population) if stats is not None else {}\n",
    "    logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "    if verbose:\n",
    "        print(logbook.stream)\n",
    "\n",
    "    # Begin the generational process\n",
    "    for gen in range(1, ngen + 1):\n",
    "        # Vary the population\n",
    "        offspring = varOr(population, toolbox, lambda_, cxpb, mutpb)\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        #fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "        fitnesses = []\n",
    "        for ind in invalid_ind:\n",
    "            fitnesses.append(Fitness_Function(ind, train_dataset, batch_size, gen))\n",
    "            \n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        if halloffame is not None:\n",
    "            halloffame.update(offspring)\n",
    "\n",
    "        # Select the next generation population\n",
    "        population[:] = toolbox.select(population + offspring, mu)\n",
    "\n",
    "        # Update the statistics with the new population\n",
    "        record = stats.compile(population) if stats is not None else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        if verbose:\n",
    "            print(logbook.stream)\n",
    "\n",
    "    return population, logbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326964c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pendulum dynamics (no friction)\n",
    "def pendulum_ode(t, y, g=9.81, L=1.0):\n",
    "    theta, omega = y\n",
    "    dtheta_dt = omega\n",
    "    domega_dt = (g / L) * np.sin(theta)\n",
    "    return [dtheta_dt, domega_dt]\n",
    "\n",
    "# Initial conditions\n",
    "theta0 = np.radians(0)  # initial angle in radians\n",
    "omega0 = 0.0            # initial angular velocity\n",
    "y0 = [theta0, omega0]\n",
    "\n",
    "# Time span and step\n",
    "\n",
    "\n",
    "def calculate_next_timestep():\n",
    "    t_span = (0, 1)\n",
    "    t_eval = np.linspace(t_span[0], t_span[1], 1000)\n",
    "    # Solve using SciPy RK45\n",
    "    sol = solve_ivp(\n",
    "        pendulum_ode,\n",
    "        t_span,\n",
    "        y0,\n",
    "        t_eval=t_eval,\n",
    "        args=(g, L),        # optional: pass g and L\n",
    "        method=\"RK45\",           # can also try \"RK23\", \"DOP853\", \"BDF\", etc.\n",
    "        rtol=1e-9,\n",
    "        atol=1e-9\n",
    "    )\n",
    "    return sol\n",
    "\n",
    "# Extract results\n",
    "theta = sol.y[0]\n",
    "omega = sol.y[1]\n",
    "accel = (9.81 / 1.0) * np.sin(theta)\n",
    "\n",
    "# Optional: convert to linear quantities\n",
    "L = 1.0\n",
    "x = L * np.sin(theta)\n",
    "v = L * omega * np.cos(theta)\n",
    "a = L * accel * np.cos(theta) - L * omega**2 * np.sin(theta)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(sol.t, theta, label=\"Angle (rad)\")\n",
    "plt.plot(sol.t, omega, label=\"Angular velocity (rad/s)\")\n",
    "plt.plot(sol.t, accel, label=\"Angular acceleration (rad/s²)\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.title(\"Inverted Pendulum (No Friction)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df74188",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Sci_computing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
